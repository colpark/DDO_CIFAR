{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Training DDO on CIFAR-10 Dataset\n",
    "\n",
    "This notebook trains a DDO (Diffusion in Domain/Operator space) model on CIFAR-10 in pixel space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PROJ_DIR\"] = '/PATH/TO/REPO/ddo'\n",
    "os.environ[\"FID_DIR\"] = '/PATH/TO/CACHE/FOLDER/fid-stats'\n",
    "os.environ[\"EXP_PATH\"] = '/PATH/TO/CACHE/FOLDER/exp'\n",
    "%cd /PATH/TO/REPO/ddo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-gpu",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import importlib\nimport sys\nimport functools\nimport math\nimport time\nimport argparse\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom tqdm.auto import tqdm  # Fixed: use tqdm.auto instead\n\nMYBACKEND = plt.get_backend()\nprint(MYBACKEND)\n\n%matplotlib inline"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-utils",
   "metadata": {},
   "outputs": [],
   "source": "from main import *\nfrom utils import datasets\nfrom utils.visualize import get_grid_image\nfrom utils.utils import Writer\n\n# Re-import tqdm correctly in case main.py imports it differently\nfrom tqdm.auto import tqdm\n\nmatplotlib.use(MYBACKEND)"
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": "args = argparse.Namespace()\n\n# seed\nargs.seed = 1\nargs.command_type = 'train'\n\n# i/o paths\nargs.exp_path = os.path.join(os.getenv('EXP_PATH', './experiments'), 'cifar10_ddo_notebook')\nargs.data = os.path.join(os.getenv('SLURM_TMPDIR', './data'), 'data')\nargs.fid_dir = os.getenv('FID_DIR', './fid_stats/cifar10')\nargs.print_every = 100\nargs.save_every = 5000\nargs.ckpt_every = 10000\nargs.eval_every = 5000\nargs.vis_every = 1000\nargs.plot = False\nargs.resume = True\nargs.checkpoint_file = 'checkpoint.pt'\n\n# optimization\nargs.train_batch_size = 128\nargs.vis_batch_size = 64\nargs.optimizer = 'adam'\nargs.lr = 0.0002\nargs.lr_rampup_kimg = 0\nargs.lr_scheduler = 'none'\nargs.ema_decay = 0.999\nargs.weight_decay = 0.\nargs.beta1 = 0.9\nargs.beta2 = 0.999\nargs.num_iterations = 100000  # Shorter for notebook demo\n\n# dataset - CIFAR-10 is 32x32 RGB\nargs.train_img_height = 32\nargs.dataset = 'cifar10'\nargs.dequantize = False\nargs.transform = None  # No transform - work in pixel space\nargs.input_dim = 3  # RGB\nargs.coord_dim = 2\nargs.centered = False\nargs.interpolation = 'bilinear'\nargs.antialias = False\n\n# model - REDUCED SIZE for CIFAR-10\nargs.model = 'fnounet2d'\nargs.modes = 16  # Reduced from 32\nargs.act = None\nargs.ch = 64  # Reduced from 128\nargs.ch_mult = (1,2,2)  # Reduced from (1,2,2,2) - one less level\nargs.num_res_blocks = 2  # Reduced from 4\nargs.dropout = 0.1\nargs.discard_resamp_with_conv = False\nargs.use_pointwise_op = True\nargs.use_radial = False\nargs.use_pos = True\nargs.norm = 'group_norm'\n\n# diffusion forward process\nargs.timestep_sampler = 'low_discrepancy'\nargs.ns_method = 'vp_cosine'\nargs.disp_method = 'sine'\nargs.sigma_blur_min = 0.05\nargs.sigma_blur_max = 0.25\n\n# gaussian process noise\nargs.gp_type = 'exponential'\nargs.gp_exponent = 2.0\nargs.gp_length_scale = 0.05\nargs.gp_sigma = 1.0\nargs.gp_modes = None\n\n# sampling\nargs.num_steps = 250\nargs.s_min = 1e-4\nargs.sampler = 'denoise'\nargs.use_clip = False\nargs.weight_method = None\n\n# evaluation\nargs.eval_img_height = 32\nargs.eval_batch_size = 256\nargs.eval_use_ema = True\nargs.eval_fid = True\nargs.eval_pr = False\nargs.eval_num_samples = 5000\nargs.eval_resize_mode = 'tensor'\nargs.eval_interpolation = 'bilinear'\nargs.eval_antialias = False\nargs.eval_cache = False\n\n# distributed training (not used in notebook)\nargs.num_proc_node = 1\nargs.num_process_per_node = 1\nargs.node_rank = 0\nargs.local_rank = 0\nargs.global_rank = 0\nargs.global_size = 1\nargs.distributed = False\nargs.master_address = '127.0.0.1'\nargs.master_port = None\n\n# batch sizes per GPU\nargs.train_batch_size_per_gpu = args.train_batch_size\nargs.eval_batch_size_per_gpu = args.eval_batch_size\nargs.batch_size_per_gpu = args.train_batch_size\n\n# create experiment directory\nos.makedirs(args.exp_path, exist_ok=True)\n\nprint(f\"Experiment path: {args.exp_path}\")\nprint(f\"Data path: {args.data}\")\nprint(f\"Training for {args.num_iterations} iterations\")\nprint(f\"\\nModel configuration:\")\nprint(f\"  Base channels: {args.ch}\")\nprint(f\"  Channel multipliers: {args.ch_mult}\")\nprint(f\"  Residual blocks: {args.num_res_blocks}\")\nprint(f\"  Fourier modes: {args.modes}\")\nprint(f\"  Expected params: ~10-50M (much smaller than before!)\")"
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "train_loader, valid_loader, num_classes = datasets.get_loaders_eval(\n",
    "    dataset=args.dataset,\n",
    "    root=args.data,\n",
    "    distributed=args.distributed,\n",
    "    batch_size=args.train_batch_size_per_gpu,\n",
    "    centered=args.centered,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {args.dataset}\")\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Visualize some training samples\n",
    "x_sample, _ = next(iter(train_loader))\n",
    "nrow = 8\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(get_grid_image(x_sample[:nrow**2], nrow=nrow, pad_value=0, padding=2, to_numpy=True))\n",
    "plt.title('CIFAR-10 Training Samples')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init-model",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize model, optimizer, and scheduler\ngen_sde, gen_sde_optimizer, gen_sde_scheduler, count, best_fid_score = init_model(args)\n\n# Count parameters (use _model not model, since model is a method)\nnum_params = count_parameters_in_M(gen_sde._model)\nprint(f\"Model parameters: {num_params:.2f}M\")\nprint(f\"Starting from iteration: {count}\")\nprint(f\"Best FID score: {best_fid_score}\")"
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup transforms\n",
    "if args.transform == \"center\":\n",
    "    args.forward = forward = to_center\n",
    "    args.reverse = reverse = to_01_clip\n",
    "elif args.transform == \"sdf\":\n",
    "    args.forward = forward = x_to_image\n",
    "    args.reverse = reverse = from_sdf_to_01_clip\n",
    "elif args.transform == \"logit\":\n",
    "    args.forward = forward = logit\n",
    "    args.reverse = reverse = inverse_logit\n",
    "else:\n",
    "    args.forward = forward = identity\n",
    "    args.reverse = reverse = identity\n",
    "\n",
    "# Writer for tensorboard\n",
    "writer = Writer(args.global_rank, args.exp_path)\n",
    "\n",
    "num_iters_per_epoch = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-loop",
   "metadata": {},
   "outputs": [],
   "source": "# Training loop\nfrom tqdm.auto import tqdm  # Re-import here since main.py overwrites it\nimport torchvision\n\nstart_time = time.time()\nepoch = count // num_iters_per_epoch\n\nfor (x, _) in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n    if count >= args.num_iterations:\n        break\n    \n    # Model to training mode\n    gen_sde.train()\n    gen_sde_optimizer.zero_grad()\n    \n    # Prepare batch\n    if args.dequantize:\n        x = x * 255 / 256 + torch.rand_like(x) / 256\n    x = args.forward(x).cuda()\n    \n    # Get coordinate grid for function space\n    v = get_mgrid(2, x.shape[-1]).repeat(x.shape[0], 1, 1, 1).cuda()\n    \n    # Compute DSM loss (Denoising Score Matching)\n    loss = gen_sde.dsm(x, v).mean()\n    \n    # Backward pass\n    loss.backward()\n    gen_sde_optimizer.step()\n    \n    # Update learning rate\n    if gen_sde_scheduler is not None:\n        gen_sde_scheduler.step()\n    \n    count += 1\n    \n    # Logging\n    if count % args.print_every == 0:\n        elapsed = (time.time() - start_time) / args.print_every\n        lr = gen_sde_optimizer.param_groups[0]['lr']\n        print(f\"Iter {count:6d} | Loss: {loss.item():.4f} | LR: {lr:.6f} | Time: {elapsed:.2f}s/iter\")\n        writer.add_scalar('train/loss', loss.item(), count)\n        writer.add_scalar('train/lr', lr, count)\n        start_time = time.time()\n    \n    # Visualization\n    if count % args.vis_every == 0:\n        gen_sde.eval()\n        with torch.no_grad():\n            # Generate samples\n            sample = sample_image(\n                gen_sde,\n                batch_size=min(64, args.vis_batch_size),\n                img_height=args.train_img_height,\n                num_steps=args.num_steps,\n                transform=None,\n                clip=True,\n                disable_tqdm=True,\n                sampler=args.sampler\n            )\n            sample = args.reverse(sample)\n            nrow = 8\n            \n            # Save to TensorBoard\n            writer.add_image(\n                'train/samples',\n                get_grid_image(sample[:nrow**2].cpu(), nrow=nrow, pad_value=0, padding=2, to_numpy=False),\n                count\n            )\n            \n            # Also save as PNG file\n            sample_dir = os.path.join(args.exp_path, 'samples')\n            os.makedirs(sample_dir, exist_ok=True)\n            torchvision.utils.save_image(\n                sample[:nrow**2],\n                os.path.join(sample_dir, f'iter_{count:06d}.png'),\n                nrow=nrow,\n                padding=2,\n                normalize=True,\n                value_range=(0, 1)\n            )\n            \n        writer.flush()\n        print(f\"Visualized samples at iter {count}\")\n        print(f\"  - TensorBoard: {args.exp_path}/tensorboard/\")\n        print(f\"  - PNG file: {sample_dir}/iter_{count:06d}.png\")\n    \n    # Save checkpoint\n    if count % args.save_every == 0:\n        if args.global_rank == 0:\n            save_checkpoint(\n                os.path.join(args.exp_path, 'checkpoint.pt'),\n                gen_sde,\n                gen_sde_optimizer,\n                gen_sde_scheduler,\n                count,\n                best_fid_score\n            )\n            print(f\"Saved checkpoint at iter {count}\")\n\nprint(f\"Training completed at iteration {count}\")"
  },
  {
   "cell_type": "markdown",
   "id": "sample-header",
   "metadata": {},
   "source": [
    "## 6. Generate Final Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final samples\n",
    "gen_sde.eval()\n",
    "\n",
    "# Switch to EMA parameters if available\n",
    "if args.eval_use_ema and hasattr(gen_sde_optimizer, 'swap_parameters_with_ema'):\n",
    "    gen_sde_optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "\n",
    "num_samples = 64\n",
    "with torch.no_grad():\n",
    "    sample = sample_image(\n",
    "        gen_sde,\n",
    "        batch_size=num_samples,\n",
    "        img_height=32,\n",
    "        num_steps=args.num_steps,\n",
    "        transform=None,\n",
    "        clip=True,\n",
    "        disable_tqdm=False,\n",
    "        sampler=args.sampler\n",
    "    )\n",
    "    sample = args.reverse(sample)\n",
    "\n",
    "# Switch back to original parameters\n",
    "if args.eval_use_ema and hasattr(gen_sde_optimizer, 'swap_parameters_with_ema'):\n",
    "    gen_sde_optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "\n",
    "# Visualize\n",
    "nrow = 8\n",
    "image = get_grid_image(sample[:nrow**2].cpu(), nrow=nrow, pad_value=0, padding=2, to_numpy=True)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(image)\n",
    "plt.title(f'Generated CIFAR-10 Samples (Iteration {count})')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(args.exp_path, f'samples_iter_{count}.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated {num_samples} samples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}