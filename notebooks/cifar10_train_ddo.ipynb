{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Training DDO on CIFAR-10 Dataset\n",
    "\n",
    "This notebook trains a DDO (Diffusion in Domain/Operator space) model on CIFAR-10 in pixel space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PROJ_DIR\"] = '/PATH/TO/REPO/ddo'\n",
    "os.environ[\"FID_DIR\"] = '/PATH/TO/CACHE/FOLDER/fid-stats'\n",
    "os.environ[\"EXP_PATH\"] = '/PATH/TO/CACHE/FOLDER/exp'\n",
    "%cd /PATH/TO/REPO/ddo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-gpu",
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import functools\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "MYBACKEND = plt.get_backend()\n",
    "print(MYBACKEND)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "from utils import datasets\n",
    "from utils.visualize import get_grid_image\n",
    "from utils.utils import Writer\n",
    "\n",
    "matplotlib.use(MYBACKEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "\n",
    "# seed\n",
    "args.seed = 1\n",
    "args.command_type = 'train'\n",
    "\n",
    "# i/o paths\n",
    "args.exp_path = os.path.join(os.getenv('EXP_PATH', './experiments'), 'cifar10_ddo_notebook')\n",
    "args.data = os.path.join(os.getenv('SLURM_TMPDIR', './data'), 'data')\n",
    "args.fid_dir = os.getenv('FID_DIR', './fid_stats/cifar10')\n",
    "args.print_every = 100\n",
    "args.save_every = 5000\n",
    "args.ckpt_every = 10000\n",
    "args.eval_every = 5000\n",
    "args.vis_every = 1000\n",
    "args.plot = False\n",
    "args.resume = True\n",
    "args.checkpoint_file = 'checkpoint.pt'\n",
    "\n",
    "# optimization\n",
    "args.train_batch_size = 128\n",
    "args.vis_batch_size = 64\n",
    "args.optimizer = 'adam'\n",
    "args.lr = 0.0002\n",
    "args.lr_rampup_kimg = 0\n",
    "args.lr_scheduler = 'none'\n",
    "args.ema_decay = 0.999\n",
    "args.weight_decay = 0.\n",
    "args.beta1 = 0.9\n",
    "args.beta2 = 0.999\n",
    "args.num_iterations = 100000  # Shorter for notebook demo\n",
    "\n",
    "# dataset - CIFAR-10 is 32x32 RGB\n",
    "args.train_img_height = 32\n",
    "args.dataset = 'cifar10'\n",
    "args.dequantize = False\n",
    "args.transform = None  # No transform - work in pixel space\n",
    "args.input_dim = 3  # RGB\n",
    "args.coord_dim = 2\n",
    "args.centered = False\n",
    "args.interpolation = 'bilinear'\n",
    "args.antialias = False\n",
    "\n",
    "# model\n",
    "args.model = 'fnounet2d'\n",
    "args.modes = 32\n",
    "args.act = None\n",
    "args.ch = 128\n",
    "args.ch_mult = (1,2,2,2)\n",
    "args.num_res_blocks = 4\n",
    "args.dropout = 0.1\n",
    "args.discard_resamp_with_conv = False\n",
    "args.use_pointwise_op = True\n",
    "args.use_radial = False\n",
    "args.use_pos = True\n",
    "args.norm = 'group_norm'\n",
    "\n",
    "# diffusion forward process\n",
    "args.timestep_sampler = 'low_discrepancy'\n",
    "args.ns_method = 'vp_cosine'\n",
    "args.disp_method = 'sine'\n",
    "args.sigma_blur_min = 0.05\n",
    "args.sigma_blur_max = 0.25\n",
    "\n",
    "# gaussian process noise\n",
    "args.gp_type = 'exponential'\n",
    "args.gp_exponent = 2.0\n",
    "args.gp_length_scale = 0.05\n",
    "args.gp_sigma = 1.0\n",
    "args.gp_modes = None\n",
    "\n",
    "# sampling\n",
    "args.num_steps = 250\n",
    "args.s_min = 1e-4\n",
    "args.sampler = 'denoise'\n",
    "args.use_clip = False\n",
    "args.weight_method = None\n",
    "\n",
    "# evaluation\n",
    "args.eval_img_height = 32\n",
    "args.eval_batch_size = 256\n",
    "args.eval_use_ema = True\n",
    "args.eval_fid = True\n",
    "args.eval_pr = False\n",
    "args.eval_num_samples = 5000\n",
    "args.eval_resize_mode = 'tensor'\n",
    "args.eval_interpolation = 'bilinear'\n",
    "args.eval_antialias = False\n",
    "args.eval_cache = False\n",
    "\n",
    "# distributed training (not used in notebook)\n",
    "args.num_proc_node = 1\n",
    "args.num_process_per_node = 1\n",
    "args.node_rank = 0\n",
    "args.local_rank = 0\n",
    "args.global_rank = 0\n",
    "args.global_size = 1\n",
    "args.distributed = False\n",
    "args.master_address = '127.0.0.1'\n",
    "args.master_port = None\n",
    "\n",
    "# batch sizes per GPU\n",
    "args.train_batch_size_per_gpu = args.train_batch_size\n",
    "args.eval_batch_size_per_gpu = args.eval_batch_size\n",
    "args.batch_size_per_gpu = args.train_batch_size\n",
    "\n",
    "# create experiment directory\n",
    "os.makedirs(args.exp_path, exist_ok=True)\n",
    "\n",
    "print(f\"Experiment path: {args.exp_path}\")\n",
    "print(f\"Data path: {args.data}\")\n",
    "print(f\"Training for {args.num_iterations} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "train_loader, valid_loader, num_classes = datasets.get_loaders_eval(\n",
    "    dataset=args.dataset,\n",
    "    root=args.data,\n",
    "    distributed=args.distributed,\n",
    "    batch_size=args.train_batch_size_per_gpu,\n",
    "    centered=args.centered,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {args.dataset}\")\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Visualize some training samples\n",
    "x_sample, _ = next(iter(train_loader))\n",
    "nrow = 8\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(get_grid_image(x_sample[:nrow**2], nrow=nrow, pad_value=0, padding=2, to_numpy=True))\n",
    "plt.title('CIFAR-10 Training Samples')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init-model",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize model, optimizer, and scheduler\ngen_sde, gen_sde_optimizer, gen_sde_scheduler, count, best_fid_score = init_model(args)\n\n# Count parameters (use _model not model, since model is a method)\nnum_params = count_parameters_in_M(gen_sde._model)\nprint(f\"Model parameters: {num_params:.2f}M\")\nprint(f\"Starting from iteration: {count}\")\nprint(f\"Best FID score: {best_fid_score}\")"
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup transforms\n",
    "if args.transform == \"center\":\n",
    "    args.forward = forward = to_center\n",
    "    args.reverse = reverse = to_01_clip\n",
    "elif args.transform == \"sdf\":\n",
    "    args.forward = forward = x_to_image\n",
    "    args.reverse = reverse = from_sdf_to_01_clip\n",
    "elif args.transform == \"logit\":\n",
    "    args.forward = forward = logit\n",
    "    args.reverse = reverse = inverse_logit\n",
    "else:\n",
    "    args.forward = forward = identity\n",
    "    args.reverse = reverse = identity\n",
    "\n",
    "# Writer for tensorboard\n",
    "writer = Writer(args.global_rank, args.exp_path)\n",
    "\n",
    "num_iters_per_epoch = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "start_time = time.time()\n",
    "epoch = count // num_iters_per_epoch\n",
    "\n",
    "for (x, _) in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "    if count >= args.num_iterations:\n",
    "        break\n",
    "    \n",
    "    # Model to training mode\n",
    "    gen_sde.train()\n",
    "    gen_sde_optimizer.zero_grad()\n",
    "    \n",
    "    # Prepare batch\n",
    "    if args.dequantize:\n",
    "        x = x * 255 / 256 + torch.rand_like(x) / 256\n",
    "    x = args.forward(x).cuda()\n",
    "    \n",
    "    # Sample timesteps\n",
    "    if args.timestep_sampler == 'low_discrepancy':\n",
    "        t = low_discrepancy_rand(x.shape[0], device=x.device)\n",
    "    else:\n",
    "        t = torch.rand(x.shape[0], device=x.device)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = diffuse(gen_sde, x, t)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    gen_sde_optimizer.step()\n",
    "    \n",
    "    # Update learning rate\n",
    "    if gen_sde_scheduler is not None:\n",
    "        gen_sde_scheduler.step()\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    # Logging\n",
    "    if count % args.print_every == 0:\n",
    "        elapsed = (time.time() - start_time) / args.print_every\n",
    "        lr = gen_sde_optimizer.param_groups[0]['lr']\n",
    "        print(f\"Iter {count:6d} | Loss: {loss.item():.4f} | LR: {lr:.6f} | Time: {elapsed:.2f}s/iter\")\n",
    "        writer.add_scalar('train/loss', loss.item(), count)\n",
    "        writer.add_scalar('train/lr', lr, count)\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # Visualization\n",
    "    if count % args.vis_every == 0:\n",
    "        gen_sde.eval()\n",
    "        with torch.no_grad():\n",
    "            # Generate samples\n",
    "            sample = sample_image(\n",
    "                gen_sde,\n",
    "                batch_size=min(64, args.vis_batch_size),\n",
    "                img_height=args.train_img_height,\n",
    "                num_steps=args.num_steps,\n",
    "                transform=None,\n",
    "                clip=True,\n",
    "                disable_tqdm=True,\n",
    "                sampler=args.sampler\n",
    "            )\n",
    "            sample = args.reverse(sample)\n",
    "            nrow = 8\n",
    "            writer.add_image(\n",
    "                'train/samples',\n",
    "                get_grid_image(sample[:nrow**2].cpu(), nrow=nrow, pad_value=0, padding=2, to_numpy=False),\n",
    "                count\n",
    "            )\n",
    "        writer.flush()\n",
    "        print(f\"Visualized samples at iter {count}\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if count % args.save_every == 0:\n",
    "        if args.global_rank == 0:\n",
    "            save_checkpoint(\n",
    "                os.path.join(args.exp_path, 'checkpoint.pt'),\n",
    "                gen_sde,\n",
    "                gen_sde_optimizer,\n",
    "                gen_sde_scheduler,\n",
    "                count,\n",
    "                best_fid_score\n",
    "            )\n",
    "            print(f\"Saved checkpoint at iter {count}\")\n",
    "\n",
    "print(f\"Training completed at iteration {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-header",
   "metadata": {},
   "source": [
    "## 6. Generate Final Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final samples\n",
    "gen_sde.eval()\n",
    "\n",
    "# Switch to EMA parameters if available\n",
    "if args.eval_use_ema and hasattr(gen_sde_optimizer, 'swap_parameters_with_ema'):\n",
    "    gen_sde_optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "\n",
    "num_samples = 64\n",
    "with torch.no_grad():\n",
    "    sample = sample_image(\n",
    "        gen_sde,\n",
    "        batch_size=num_samples,\n",
    "        img_height=32,\n",
    "        num_steps=args.num_steps,\n",
    "        transform=None,\n",
    "        clip=True,\n",
    "        disable_tqdm=False,\n",
    "        sampler=args.sampler\n",
    "    )\n",
    "    sample = args.reverse(sample)\n",
    "\n",
    "# Switch back to original parameters\n",
    "if args.eval_use_ema and hasattr(gen_sde_optimizer, 'swap_parameters_with_ema'):\n",
    "    gen_sde_optimizer.swap_parameters_with_ema(store_params_in_ema=True)\n",
    "\n",
    "# Visualize\n",
    "nrow = 8\n",
    "image = get_grid_image(sample[:nrow**2].cpu(), nrow=nrow, pad_value=0, padding=2, to_numpy=True)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(image)\n",
    "plt.title(f'Generated CIFAR-10 Samples (Iteration {count})')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(args.exp_path, f'samples_iter_{count}.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated {num_samples} samples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}